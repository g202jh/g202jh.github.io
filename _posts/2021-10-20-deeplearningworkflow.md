---
layout: post
title:  "머신러닝의 보편적 워크플로우"
---

# **머신러닝의 보편적 워크플로우**

*   머신러닝 문제를 구성하는 단계
*   작업 모델 개발 단계
*   생산환경에 모델을 전개하는 단계 및 유지

현실 세계에서는 레이블에 지정된 데이터 세트가 없는 경우가 많고, 모델 교육을 즉시 시작할 수도 없다.

**윤리 관련 참고 사항**

기술은 결코 중립일 수 없다. 만약 당신의 연구가 세상에 영향을 미친다면, 이 영향은 도덕적인 방향을 가져야 한다. 

기술적인 선택 또한 윤리적 선택이다. 당신의 작품이 뒷받침하기를 바라는 가치에 대해 항상 숙고해야 한다.

만약 keras.datasets에서 올바른 데이터 세트를 가져와 일부 딥러닝 모델을 적합시킬 수 있다면 매우 편리할 것이다. 그러나 현실 세계에서는 처음부터 다시 시작해야 할 것이다.



머신러닝의 보편적 워크플로는 크게 세 부분으로 구성된다.

*   과제 정의 : 문제 영역과 고객이 질문한 내용을 뒷받침하는 비즈니스 논리를 이해합니다. 데이터 집합을 수집하고 데이터가 나타내는 바를 파악한 후 작업에서 성공을 측정하는 방법을 선택합니다.
*   모델 개발 : 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 이길 수 있는 간단한 기준선을 선택한 다음, 오버핏할 수 있는 일반화 능력을 갖춘 첫 번째 모델을 교육한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다.
*   모델 배치 : 이해 관계자에게 작업물을 전달하고, 웹 서버, 모바일 앱, 웹 페이지 또는 임베디드 장치로 모델을 전달하며, 야생에서의 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집하기 시작합니다

## **과제 정의**

자신이 하고 있는 일의 맥락을 깊이 이해해야 한다.

왜 이문제를 해결하려고 하는지, 어떤 가치를 창출할 수 있는지, 모델이 어떻게 사용될 것이며 어떤 종류의 데이터를 사용할 수 있는지...

### **문제 틀 짜기**

머신러닝 문제를 구체화하려면 일반적으로 이해관계자들과의 많은 상세한 논의가 필요하다. 

우리가 가져야 할 마음가짐은

*   입력 데이터는 어떻게 되는지? 무엇을 예측하려고 하는 것인지? 예를 들어 영화 리뷰와 정서 주석이 모두 있는 경우에만 영화 리뷰의 감정을 분류하는 방법을 배울 수 있습니다.

 이와 같이, 이 단계에서 데이터 가용성은 보통 제한 요소이다. 대부분의 경우 사용자가 직접 새 데이터셋을 수집하고 주석을 달아야 한다.

*   어떤 종류의 머신러닝 과제를 마주하고 있는지? 이항 분류, 다중 클래스 분류, 스칼라 회귀, 벡터 회귀, 멀티클래스, 멀티라벨 분류, 이미지 분할, 순위, 클러스터링, 생성 또는 강화 학습과 같은 다른 것 등등...

*   어던 시스템이 이미 구축되어 있는지, 어떻게 작동하는지 확실히 이해해야 한다.



따라서 일단 조사를 마쳤으면,우리의 입력이 무엇일지, 우리의 목표가 무엇인지, 그리고 문제가 어떤 종류의 머신러닝 과제로 매핑되는지 알아야 한다. 

*   입력이 주어지면 목표값을 예측할 수 있다는 가설을 세운다.

*   사용할 수 있는 데이터(또는 곧 수집할 데이터)가 입력과 목표값 사이의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세운다.

**주의:** 머신러닝으로 모든 문제를 해결할 수 있는 것은 아니다. 입력 X와 대상Y의 예를 종합했다고 해서 X가 Y를 예측하기에 충분한 정보를 포함하고 있다는 것을 의미하지는 않는다.

### **데이터셋 수집**

작업의 특성을 이해하고 입력과 대상이 무엇인지 알게 되면 대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 부분인 데이터 수집이 필요한 시점이다.

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후에는 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요하다.

때때로 음악 추천 작업이나 클릭률 예측 작업의 경우처럼 주석이 자동으로 검색될 수 있다.

하지만 대부분은 데이터에 주석을 직접 달아야 합니다. 이는 노동력을 많이 필요로 한다.



**데이터 주석 인프라에 투자**

데이터 주석 과정에 따라 목표물의 품질이 결정되고, 이는 다시 모형의 품질을 결정한다. 사용할 수 있는 옵션을 신중하게 생각해야 한다.

*   데이터에 주석을 직접 달아야 하는지
*   label을 모으기 위해 Mechanical Turk와 같은 크라우드소싱 플랫폼을 사용해야 할지
*   데이터 레이블링 전문 회사의 서비스를 이용할지



**non-representative 데이터**

머신러닝 모델은 이전에 본 것과 비슷한 입력만 이해할 수 있다. 따라서 교육에 사용되는 데이터가 생산 데이터를 대표해야 한다. 이 문제는 모든 데이터 수집의 기반이 작동해야 한다.

교육 데이터는 생산 데이터를 대표하지 않습니다. 가능하면 모델이 사용될 환경에서 직접 데이터를 수집합니다. 

예를 들어, 영화 감상 분류 모델은 옐프 레스토랑 리뷰나 트위터 상태 업데이트가 아닌 새로운 IMDB 리뷰에 사용되어야 한다. 트윗의 감성을 평가하려면 프로덕션에서 예상하는 것과 유사한 사용자 집합에서 실제 트윗을 수집하고 주석을 다는 것부터 시작해야 한다. 프로덕션 데이터에 대한 교육이 가능하지 않다면 교육 데이터와 프로덕션 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 한다.



우리가 알아야 할 관련 현상은 개념 드리프트이다. 거의 모든 실제 문제, 특히 사용자 생성 데이터를 다루는 문제에서 개념 드리프트가 발생한다. 

개념 드리프트는 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생한다. 2013년에 훈련받은 음악 추천 엔진은 오늘날 그다지 효과적이지 않을 수 있다. 마찬가지로, 함께 작업한 IMDB 데이터 집합도 2011년에 수집되었으며, 이 데이터 집합으로 훈련된 모델은 시간이 지남에 따라 어휘, 표현 및 영화 장르가 발전함에 따라 2012년의 리뷰와 비교하여 2020년의 리뷰에서 제대로 수행되지 못할 가능성이 높다.

개념 표류는 신용 카드 사기 탐지와 같은 적대적 맥락에서 특히 극심하며, 사기 패턴은 실질적으로 매일 변한다. 빠른 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재교육이 필요하다.

머신 러닝은 훈련 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있다는 것을 명심해야 한다.

미래를 예측하기 위해 과거 데이터에 대해 훈련된 머신러닝을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것이다. 

하지만 대부분은 그렇지 않은 경우가 많다.

### **데이터 이해**

데이터셋을 블랙박스로 취급하는 것은 매우 좋지 않다. 모델을 교육하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고(기능 엔지니어링에 정보를 제공) 잠재적인 문제를 선별해야 한다.

*   데이터에 이미지 또는 자연어 텍스트가 포함된 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴보기

*   데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악하기

*   데이터에 위치 정보가 포함되어 있으면 지도에 표시하기


*   항목 추가



## **모델 개발**

진행 상황을 어떻게 측정할 것인지 알고 나면 모델 개발을 시작할 수 있다. 

대부분의 튜토리얼과 연구 프로젝트는 이것이 이미 수행된 것으로 가정되는 문제 정의 및 데이터 세트 수집을 건너뛰고 다른 사람이 처리하는 것으로 가정하는 모델 배치 및 유지 보수를 건너뛴다고 가정한다.

### **데이터 준비**

딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않는다. 

데이터 전처리는 마주한 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 한다. 

여기에는 벡터화, 정규화 또는 결측값 처리가 포함된다. 많은 사전 처리 기술은 도메인마다 다르다.(예: 텍스트 데이터 또는 이미지 데이터) 


**벡터화**

신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특별한 경우 정수나 문자열의 텐서)여야 한다. 소리, 이미지, 텍스트 등 필요한 데이터가 무엇이든 먼저 텐서로 변환해야 합니다. 이 단계를 **데이터 벡터화**라고 한다. 

예를 들어, 정수 목록(단어 시퀀스를 나타냄)으로 표현된 텍스트에서 시작하여 원핫 인코딩을 사용하여 float32 데이터의 텐서로 변환했다. 숫자를 분류하고 집값을 예측한 예에서는 이미 데이터가 벡터화된 형태로 들어왔기 때문에 이 단계를 건너뛸 수 있다.

**value 정규화**

MNIST 숫자 분류 예제에서는 0-255 범위의 정수로 인코딩된 영상 데이터에서 시작하여 그레이스케일 값을 인코딩했었다. 이 데이터를 네트워크에 입력하기 전에 부동소수점 값이 0-1 범위에 오르게 하려면 부동소수점 값을 float32로 캐스팅하고 255로 나누어야 한다. 마찬가지로 집값을 예측할 때 부동소수점 값이 작고 정수 값이 상당히 큰 다양한 범위의 특성에서 시작했었다. 이 데이터를 네트워크에 입력하기 전에 표준 편차가 1이고 평균이 0이 되도록 각 특성를 독립적으로 정규화해야 한다.

일반적으로 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 사용하는 신경망 데이터나 이기종 데이터(예: 한 특징이 0-1이고 다른 특징이 100-200인 데이터)에 입력하는 것은 안전하지 않다. 이렇게 하면 대규모 그라데이션 업데이트가 트리거되어 네트워크가 수렴되지 않을 수 있다. 네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 한다.

*   작은 값 사용 : 일반적으로 대부분의 값은 0-1 범위여야 한다.
*   균일성 : 즉, 모든 특성이 거의 동일한 범위의 값을 가져야 한다.


또한 다음과 같은 엄격한 정규화 방법이 일반적이며 항상 필요한 것은 아니지만 도움이 될 수 있다.(예: 숫자 분류 예제)


*   0의 평균을 가지도록 각 형상을 독립적으로 정규화한다.
*   표준 편차가 1이 되도록 각 형상을 독립적으로 정규화한다.




**결측값 처리**

때때로 데이터에 결측값이 있을 수 있다. 예를 들어, 집값의 예에서 첫 번째 특징(데이터의 지수 0열)은 1인당 범죄율이었다. 만약 이 특성이 모든 샘플에서 사용할 수 없다면 훈련 또는 테스트 데이터에 결측값이 있게 된다.

특성을 완전히 없앨 수도 있지만 반드시 그럴 필요는 없다.

*   특성이 범주형인 경우 "값이 누락됨"을 의미하는 새 범주를 작성하는 것이 안전하다. 모델은 대상에 대해 이것이 내포하는 의미를 자동으로 학습한다.
*   특성이 숫자인 경우, 특성에 의해 형성된 잠재 공간에 불연속성이 생성되어 해당 형상에 대해 훈련된 모델이 일반화하기가 더 어려워질 수 있으므로 "0"과 같은 임의 값을 입력하면 안된다. 대신 결측값을 데이터 집합의 특성에 대한 평균값 또는 중간값으로 바꾸는 것을 생각한다. 다른 특성의 값이 주어진 특성의 값을 예측하도록 모델을 교육할 수도 있다.

테스트 데이터에 범주형 결측 특성이 있을 것으로 예상되지만 네트워크가 결측값 없이 데이터에 대해 학습된 경우, 네트워크는 결측값을 무시하는 방법을 배우지 않는다. 이 경우 누락된 항목이 있는 교육 샘플을 인위적으로 생성해야 한다. 일부 훈련 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 특성 중 일부를 삭제해야 한다.


### **평가 프로토콜 선택**

모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내릴 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 의해 안내된다. 검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것이다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요하다.

일반적인 세 가지 평가 프로토콜

*   홀드아웃 유효성 검사 세트 유지: 데이터가 많을 때 사용하는 방법
*   K-폴드 교차 검증 수행 : 홀드아웃 검증을 신뢰할 수 없을 정도로 표본 수가 적을 때 선택
*   반복 K-폴드 검증 수행 : 데이터가 거의 없을 때 매우 정확한 모델 평가를 수행

이것들 중 하나만 골라 사용한다. 대부분의 경우 첫 번째 방법을 사용한다. 앞에서 배웠듯이, 항상 검증 세트의 대표성에 유의하고 훈련 세트와 검증 세트 사이에 중복 샘플이 없도록 주의해야 한다.


### **손실 함수**

올바른 손실 함수 선택

문제에 대한 성공을 측정하는 metric에 대해 직접 최적화하지 못하는 경우가 많다. metric을 손실 함수로 바꾸는 쉬운 방법이 없을 때도 있다. 결국 손실 함수는 데이터의 미니 배치(이상적으로 손실 함수는 단일 데이터 포인트만큼만 계산 가능해야 함)가 주어져야 하며, 역전파를 사용하여 네트워크를 훈련시킬 수 없어야 한다. 

예를 들어, 널리 사용되는 분류 지표 ROC AUC는 직접 최적화될 수 없다. 따라서 분류 작업에서 교차 엔트로피와 같은 ROC AUC의 proxy metric에 최적화하는 것이 일반적이다. 일반적으로 교차 엔트로피가 낮을수록 ROC AUC가 더 높아진다.



**표 : 모형에 적합한 마지막 계층 활성화 및 손실 함수 선택**

|Problem type|마지막-layer 활성화 함수|손실 함수|
|------------|:----------------------:|:-------:|
|이진 분류|sigmoid|binary_crossentropy |
|다중 클래스, 단일라벨 분류|softmax|categorical_crossentropy|
|다중 클래스, 다중라벨 분류|sigmoid|binary_crossentropy|
|임의의 값으로 회귀|None|평균제곱오차(mse)|

### **과대 적합 모델 개발**

이상적인 모델은 과대적합과 과소적합 사이의 경계에 서있는 모델이다.

얼마나 큰 모델이 필요한지 알아내려면, 먼저 과대적합 모델을 개발해야 한다. 

1.   layers 추가
2.   더 큰 layers 만들기
3.   더 많은 epochs 훈련시키기.

훈련 손실 및 검증 손실은 물론 관심 있는 metric에 대한 훈련 및 검증 값도 항상 모니터링 해야 한다. 검증 데이터에 대한 모델의 성능이 저하되기 시작하면 과대적합이 이루어진 것이다.


### **모델 정규화 및 조정**

일단 과대적합을 할 수 있게 되면, 올바른 길을 가고 있다는 것이다. 이때 일반화 성능을 최대화하는 것이 목표이다.

이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고 훈련하고 검증 데이터(현 시점에서 테스트 데이터가 아님)를 평가한 다음 다시 수정하고 반복한다. 

*   다른 아키텍처를 사용 : layers 추가 또는 제거.
*   dropout 추가
*   모형이 작으면 L1 또는 L2 정규화 추가.
*   최적의 구성을 찾기 위해 다양한 하이퍼 파라미터(예: 계층당 단위 수 또는 최적화 프로그램의 학습 속도)를 사용.

Keras를 사용하면 위 작업의 상당 부분을 자동화할 수 있다.

검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모델에 유출된다. 몇 번만 반복해도 상관없지만, 여러 반복에 걸쳐 체계적으로 수행되면 검증 데이터에 대해 직접 교육을 받은 모델이 없음에도 불구하고 결국 모델이 검증 프로세스에 과도하게 적합하게 된다. 따라서 평가 과정의 신뢰성을 떨어뜨리게 된다.

좋은 모델 구성을 만들었으면 사용 가능한 모든 데이터(훈련 및 검증)에 대해 최종 생산 모델을 훈련하고 테스트 세트에서 마지막으로 평가할 수 있다. 

테스트 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 더 나쁜 것으로 판명되면 이는 검증 절차를 신뢰할 수 없거나 모델의 매개 변수를 조정하는 동안 검증 데이터에 과대적합하기 시작했음을 의미한다. 이 경우 K-폴드 반복 유효성 검사와 같은 안정적인 평가 프로토콜로 전환할 수 있다.

## **모델 배포**

### **이해 관계자에게 작업을 설명하고 기대치를 설정**

성공과 고객 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것입니다. 실제로 제공하는 시스템은 그 그림의 절반에 불과합니다. 나머지 절반은 출시 전 적절한 기대치를 설정하고 있다.

**추론 모형 최적화**

사용 가능한 전력 및 메모리(스마트폰 및 임베디드 장치)에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 추론을 위해 모델을 최적화하는 것이 특히 중요합니다. TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 합니다.

*   가중치 가지치기: 가중치 텐서의 모든 계수가 예측에 동일하게 기여하는 것은 아니다. 가장 중요한 항목만 유지하면 모델의 계층에서 매개변수 수를 크게 줄일 수 있다. 따라서 성능 metric에서 적은 비용으로 모델의 메모리 및 컴퓨팅 설치 공간을 줄일 수 있다. 적용할 가지치기 양을 조정하면 크기와 정확도 사이의 균형을 조정할 수 있습니다.

*   가중치 정량화: 딥러닝 모델은 단일 정밀 부동 소수점(float32 ) 가중치를 사용하여 훈련된다. 그러나 가중치를 8비트 부호 정수(int8)로 정량화하면 4배 작지만 원래 모델의 정확도에 가까운 추론 전용 모델을 얻을 수 있다.



### **모델 유지 관리**

마지막으로, 영원한 모델은 없다. 컨셉 드리프트에 대해 이미 배웠다. 시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하된다. .

모델이 출시되자마자 모델을 대체할 다음 세대를 교육할 준비를 해야한다.

*   데이터를 계속 수집하고 주석을 달 수 있으며 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있다. 특히 현재 모형에 대해 분류하기 어려운 표본을 수집하는 데 특히 주의해야 한다. 이러한 표본은 성능을 향상시키는 데 도움이 될 가능성이 높기 때문.

